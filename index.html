<!DOCTYPE html>
  <html lang="en">
    <head>
      <title>Spring Seminar 2020</title>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <link rel="stylesheet" href="static/styles/index.css"> <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> <link rel="stylesheet" media="screen" href="https://fontlibrary.org/face/hk-grotesk" type="text/css"/>
        <link rel="icon" href="static/images/favicon.png">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.1/css/all.css" integrity="sha384-O8whS3fhG2OnA5Kas0Y9l3cfpmYjapjI0E4theH4iuMD+pLhbf6JI0jIMfYcK3yZ" crossorigin="anonymous">
        <link href="https://afeld.github.io/emoji-css/emoji.css" rel="stylesheet"> 
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">
         <!--   JS IMPORTS   -->
        <script src="https://code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mustache.js/2.3.0/mustache.min.js" integrity="sha256-iaqfO5ue0VbSGcEiQn+OeXxnxAMK2+QgHXIDA5bWtGI=" crossorigin="anonymous"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.17.1/moment.min.js" integrity="sha256-Gn7MUQono8LUxTfRA0WZzJgTua52Udm1Ifrk5421zkA=" crossorigin="anonymous"></script>
<!--         <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css"/> -->
        <link rel="stylesheet" href="static/styles/prism.min.css"/>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/prism.min.js"></script>
          <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
    </head>

    <style>
      .div-1 {
          background-color: #FCFCFC;
      }
      
      .div-2 {
        background-color: #ABBAEA;
      }
      
      .div-3 {
        background-color: #FBD603;
      }
      p.rank{
        padding-left:50px;
      }
      body {
        font-family: 'HankenGroteskRegular';
        background-color:#E0E0E0;
      }
    </style>
      <body>
        <!-- HEADER -->
        <div class="header">
          <h1>
            <img src="static/images/asu_apg_logo.png" width="10%" draggable="false">  <b>Seminar Series</b>
          </h1>
          <h2> <i> Spring 2021: Frontier topics in Vision and/or Language </i></h3>
          <a href="https://calendar.google.com/calendar/u/0?cid=Y192aDNjcmJmOWI0dG0zY2dzZml1dmhpYmoyOEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t"> Add to Calendar (.ics) </a> &nbsp;
          <a href="https://yezhouyang.engineering.asu.edu/"> Active Perception Group</a>
        </div>

        <!-- BODY -->
        <div class="container">
          <div class="description">
            <h3>About the Seminar </h3>
            

            <p>
              We are excited to host the first installment of the seminar series, virtually via Zoom.
              In Spring 2021, we will feature researchers working at the forefront of topics in vision and language.  
              The schedule of talks is listed below, and will be updated with more details soon. 
              <br><br>

              <i>For participants outside ASU:</i>  Please DM Yezhou Yang on <a href="https://twitter.com/Yezhou_Yang">Twitter</a>, or via <a href="mailto:yz.yang@asu.edu"> email </a>, for access to the Zoom link.  
            </p> 
          </div>
        </div>

        <div class="container">
          <div class="description">
            <h3>Schedule </h3>
            <table class="border-table">
              <tr class="border-table">
                <td style="padding:10px;width:8%;vertical-align:top"><b>Date</b></td>
                <td style="padding:10px;vertical-align:top"><b>Speaker</b></td>
                <td style="padding:10px;width:40%;vertical-align:top"><b>Talk Summary</b></td>


              </tr>
              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Jan 18</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/zhou_yu.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="http://zhouyu.cs.ucdavis.edu/">Zhou Yu</a></h4>
                        <i>
                          Zhou Yu is an Assistant Professor in CS department at Columbia University. She obtained her Ph.D. from Carnegie Mellon University in 2017.  Zhou has built various dialog systems that have a real impact, such as a job interview training system, a depression screening system, and a second language learning system. Her research interest includes dialog systems, language understanding and generation, vision and language, human-computer interaction, and social robots. Zhou received an ACL 2019 best paper nomination, featured in Forbes 2018 30 under 30 in Science, and won the 2018 Amazon Alexa Prize.
                        </i>
                      </td>
                      
                    </tr>
                  </table>
                </td>
                <td style="padding:10px 10px 10px 10px;">
                  <h4>Personalized Persuasive Dialog Systems</h4>
                    <i>Abstract:</i> Dialog systems such as Alexa and Siri are everywhere in our lives. They can complete tasks such as booking flights, making restaurant reservations and training people for interviews. These systems are passively follow-along human needs.  What if the dialog systems have a different goal than users. We introduce dialog systems that can persuade users to donate to charities. We further improve the dialog model's coherence by tracking both semantic actions and conversational strategies from dialog history using finite-state transducers. Finally, we analyze some ethical concerns and human factors in deploying personalized persuasive dialog systems.
                </td>
              </tr>

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Jan 27</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/fuxin_li.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="http://web.engr.oregonstate.edu/~lif/">Fuxin Li</a></h4>
                        <i>
                          Dr. Fuxin Li is currently an assistant professor in the School of Electrical Engineering and Computer Science at Oregon State University. Before that, he has held research positions in University of Bonn and Georgia Institute of Technology. He had obtained a Ph.D. degree in the Institute of Automation, Chinese Academy of Sciences in 2009. He has won the NSF CAREER award, (co-)won the PASCAL VOC semantic segmentation challenges from 2009-2012, and led a team to the 4th place finish in the DAVIS Video Segmentation challenge 2017. He has published more than 50 papers in computer vision, machine learning and natural language processing. His main research interests are deep learning, video object segmentation, multi-target tracking, point cloud deep networks, adversarial deep learning and human understanding of deep learning.
                        </i>
                      </td>
                    </tr>
                  </table>
                </td>
                <td style="padding:10px 10px 10px 10px;">
                  <h4>Some Understandings and New Designs of Convolutional Networks</h4>
                    <i>Abstract:</i>
                    In this talk we will be talking about some of our recent work in understanding and creating new architectures for convolutional networks, which have achieved great success in computer vision in the last decade but is also showing its weaknesses and might be getting to a point that might require an overhaul to drive deep learning to a new level. We will start by summarizing our various endeavors and lessons learned on understanding the mechanisms of decision-making convolutional networks, with the goal of representing the inner workings of them succinctly and visualizing those to the users, with a focus of gradually unveiling more structural elements of the decision-making and walking away from traditional saliency maps.

                    Afterwards, we would introduce some of our novel directions on overhauling convolutional networks. The first direction is to break the grid structure that these networks usually rely on, which led to considerable successes but also a lack of flexibility to scale and rotation invariance, as well as restricted generalization to more types of data. Our proposed PointConv breaks those barriers by estimating the nonlinear convolution function by a neural network, hence allowing convolution to be applied on point sets that are distributed arbitrarily in a low-dimensional Euclidean space. This includes, but is not limited to 3D point clouds, as the work can also be applied back to 2D images to achieve greater robustness to scales, as well as other types of data such as weather stations and units in real-time strategy games.

                    Finally, we would introduce a new approach to better estimate uncertainty in neural networks. This approach does not simply train a neural network, but it trains a generator of neural networks which can generate a diverse distribution of networks that perform at a similar accuracy. Disagreement among these generated networks can help us to estimate the intrinsic uncertainty of these networks, avoiding overconfidence and applicable to many scenarios such as outlier detection, adversarial robustness and better exploration in reinforcement learning.
                </td>
              </tr>

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Feb 03</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/vicente_ordonez.jpg" width="140px"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://www.vicenteordonez.com/">Vicente Ordóñez</a></h4>
                        <i>
                          Dr Vicente Ordóñez Román is an Assistant Professor in at the University of Virginia.
                          Prior to this, he was a Visiting Professor at Adobe Research and Visiting Researcher at the Allen Institute for AI. 
                          He received his Ph.D. in Computer Science at the University of North Carolina at Chapel Hill in 2015, an MS in Computer Science at Stony Brook University (SUNY), and an engineering degree at the Escuela Superior Politécnica del Litoral in Ecuador.

                          Vicente's research interests are in analyzing, and mining useful human insights from enormous amounts of images with associated text to improve visual recognition; building efficient visual recognition models that can perform high-level perceptual tasks; and fairness and accountability in machine learning applications. 
                          <br>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Feb 10</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/xialong_wang.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://xiaolonw.github.io/">Xiaolong Wang</a></h4>
                        <i>
                          Dr Xiaolong Wang is an Assistant Professor at UC San Diego.  
                          He was a postdoctoral fellow at UC Berkeley with Alexei Efros and Trevor Darrell,
                          and received his Ph.D. in Robotics from Carnegie Mellon University in 2019;
                          MS from Sun Yat-Sen University in 2014; 
                          and B.S. from South China Agricultural University in 2011.

                          Xiaolong is interested in Computer Vision, Machine Learning and Robotics, specifically on the topics of Self-Supervised Learning, Video Understanding, Common Sense Reasoning, RL and Robotics. 
                          <br>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Feb 15</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/abhishek_das.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://abhishekdas.com/">Abhishek Das</a></h4>
                        <i>
                          Dr Abhishek Das is a Research Scientist at Facebook AI Research.
                          Previously he received his Ph.D. in Computer Science at Georgia Tech, advised by Dhruv Batra, and working closely with Devi Parikh. He received his bachelor's degree from Indian Institute of Technology at Roorkee.

                          Abhishek's research focuses on deep learning and its applications in climate change, and in building agents that can see (computer vision), think (reasoning/interpretability), talk (language modeling), and act (reinforcement learning). 
                          <br>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>              

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Feb 22</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/xin_wang.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://eric-xw.github.io/">Xin (Eric) Wang</a></h4>
                        <i>
                          Dr Xin (Eric) Wang is an Assistant Professor of Computer Science and Engineering at UC Santa Cruz. 
                          He obtained his Ph.D. degree from UC Santa Barbara and Bachelor's degree from Zhejiang University, both in Computer Science. 

                          Eric's research interests include Natural Language Processing, Computer Vision, and Machine Learning, with an emphasis on building embodied AI agents that can communicate with humans using natural language to perform real-world tasks. 
                          <br>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Mar 01</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/damien_teney.png" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://www.damienteney.info/">Damien Teney</a></h4>
                        <i>
                          Dr Damien Teney is a Senior Researcher at the Australian Institute for Machine Learning, part of the University of Adelaide.  
                          He was previously affiliated with Carnegie Mellon University (USA), the University of Bath (UK), and the University of Innsbruck (Austria). 
                          Damien received his Ph.D. in Computer Science at the University of Liège (Belgium), advised by Justus Piater.
                          His research interests are at the intersection of computer vision and machine learning. 
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Mar 08</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/muhao_chen.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://muhaochen.github.io/">Muhao Chen</a></h4>
                        <i>
                          Dr Muhao Chen is a Computer Scientist at the Information Science Institute at University of Southern California.  
                          Previously he was a Postdoctoral Fewllo with Dan Roth at University of Pennsylvania.  
                          Muhao received his Ph.D. from UCLA in 2019 and B.S. from Fudan University in 2014. 
                          His research focuses developing knowledge-aware learning systems for processing structured and unstructured data, and extending their applications to natural language understanding, knowledge base construction, computational biology and medical informatics.
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Mar 22</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/stefan_lee.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="http://web.engr.oregonstate.edu/~leestef/">Stefan Lee</a></h4>
                        <i>
                          Dr Stefan Lee is an Assistant Professor in EECS at Oregon State University. 
                          Previously he was a Research Scientist at Georgia Tech, and a Post-Doctoral Associate at Virginia Tech with Dhruv Batra.
                          He received his Ph.D. in Computer Science from Indiana University in 2016, and B.S. from University of West Florida in 2011.

                          Stefan's research focus is the development of agents that can perceive their environment and communicate about this understanding with humans in order to coordinate their actions to achieve mutual goals -- in short, agents that can see, talk, and act.

                          <br>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>        

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Mar 29</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/yin_li.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://www.biostat.wisc.edu/~yli/">Yin Li</a></h4>
                        <i>
                          Dr Yin Li an Assistant Professor in the Department of Biostatistics and Medical Informatics and affiliate faculty in the Department of Computer Sciences at the University of Wisconsin-Madison. 
                          Previously, he obtained his PhD (with James M. Rehg) from the Georgia Institute of Technology and was a Postdoctoral Fellow (with Abhinav Gupta) at Carnegie Mellon University. 

                          Yin's primary research focus is computer vision, and is also interested in the applications of vision and learning for mobile health. His group develops methods and systems to automatically analyze human activities for healthcare applications. 
                          <br>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr> 


              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Apr 05</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/adriana_kovashka.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://people.cs.pitt.edu/~kovashka/">Adriana Kovashka</a></h4>
                        <i>
                          Dr Adriana Kovashka is an Assistant Professor in Computer Science at the University of Pittsburgh. 
                          She received her Ph.D. from the University of Texas at Austin in 2014 where she worked with Kristen Grauman, and B.A. in Computer Science and Media Studies from Pomona College, CA. 

                          Adriana's primary research area is computer vision, with overlap in machine learning, information retrieval, crowdsourcing, and natural language processing. Her work examines approaches for improving image retrieval with semantic visual attributes, and improving the communication between human and machine. 

                          <br>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>

             
                
            </table>
            </p> 
          </div>
        </div>

        <div class="container">
          <div class="hosts">
            <h3>Hosts </h3>
            <table align="center">
              <tr>
                <td class="person">
                  <a href="https://yezhouyang.engineering.asu.edu/"><b>Yezhou Yang</b></a>
                  <img src="static/images/yezhou.jpg" height="140px" class="rounded-corner"></a>
                </td>
                <td class="person">
                  <a href="https://www.public.asu.edu/~tgokhale/"><b>Tejas Gokhale</b></a>
                  <img src="static/images/tgokhale.png" height="140px" class="rounded-corner"></a>
                </td>
                <td class="person">
                  <a href="https://pratyay-banerjee.github.io/"><b>Pratyay Banerjee</b></a>
                  <img src="static/images/pratyay.jpg" height="140px" class="rounded-corner"></a>
                </td>
                <td class="person">
                  <a href="https://www.public.asu.edu/~zfang29/"><b>Zhiyuan Fang</b></a>
                  <img src="static/images/jacob.jpg" height="140px" class="rounded-corner"></a>
                </td>
                <td class="person">
                  <a href="https://www.public.asu.edu/~cbaral/"><b>Chitta Baral</b></a>
                  <img src="static/images/chitta.jpg" height="140px" class="rounded-corner"></a>
                </td>
              </tr>
            </table>

          </div>
          <p align='right'><i>Website maintained by Tejas Gokhale </i> </p>
        </div>



          </body>
      </html>
<script type="text/javascript">
  .white-bg{
    background:#ffffff !important;
}
</script>