<!DOCTYPE html>
  <html lang="en">
    <head>
      <title>Spring Seminar 2020</title>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <link rel="stylesheet" href="static/styles/index.css"> <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> <link rel="stylesheet" media="screen" href="https://fontlibrary.org/face/hk-grotesk" type="text/css"/>
        <link rel="icon" href="static/images/favicon.png">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.1/css/all.css" integrity="sha384-O8whS3fhG2OnA5Kas0Y9l3cfpmYjapjI0E4theH4iuMD+pLhbf6JI0jIMfYcK3yZ" crossorigin="anonymous">
        <link href="https://afeld.github.io/emoji-css/emoji.css" rel="stylesheet"> 
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">
         <!--   JS IMPORTS   -->
        <script src="https://code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mustache.js/2.3.0/mustache.min.js" integrity="sha256-iaqfO5ue0VbSGcEiQn+OeXxnxAMK2+QgHXIDA5bWtGI=" crossorigin="anonymous"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.17.1/moment.min.js" integrity="sha256-Gn7MUQono8LUxTfRA0WZzJgTua52Udm1Ifrk5421zkA=" crossorigin="anonymous"></script>
<!--         <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/themes/prism.min.css"/> -->
        <link rel="stylesheet" href="static/styles/prism.min.css"/>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.0/prism.min.js"></script>
          <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
    </head>

    <style>
      .div-1 {
          background-color: #FCFCFC;
      }
      
      .div-2 {
        background-color: #ABBAEA;
      }
      
      .div-3 {
        background-color: #FBD603;
      }
      p.rank{
        padding-left:50px;
      }
      body {
        font-family: 'HankenGroteskRegular';
        background-color:#E0E0E0;
      }
    </style>
      <body>
        <!-- HEADER -->
        <div class="header">
          <h1>
            <img src="static/images/asu_apg_logo.png" width="10%" draggable="false">  <b>Seminar Series</b>
          </h1>
          <h2> <i> Spring 2021: Frontier topics in Vision and/or Language </i></h3>
          <a href=""> Add to Calendar (.ics) </a> &nbsp;
          <a href="https://yezhouyang.engineering.asu.edu/"> Active Perception Group</a>
        </div>

        <!-- BODY -->
        <div class="container">
          <div class="description">
            <h3>About the Seminar </h3>
            

            <p>
              We are excited to host the first installment of the seminar series, virtually via Zoom.
              In Spring 2021, we will feature researchers working at the forefront of topics in vision and language.  
              The schedule of talks is listed below, and will be updated with more details soon. 
              <br><br>

              <i>For participants outside ASU:</i>  Please DM Yezhou Yang on <a href="https://twitter.com/Yezhou_Yang">Twitter</a>, or via <a href="mailto:yz.yang@asu.edu"> email </a>, for access to the Zoom link.  
            </p> 
          </div>
        </div>

        <div class="container">
          <div class="description">
            <h3>Schedule </h3>
            <table class="border-table">
              <tr class="border-table">
                <td style="padding:10px;width:8%;vertical-align:top"><b>Date</b></td>
                <td style="padding:10px;vertical-align:top"><b>Speaker</b></td>
                <td style="padding:10px;width:40%;vertical-align:top"><b>Talk Summary</b></td>


              </tr>
              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Jan 18</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/zhou_yu.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="http://zhouyu.cs.ucdavis.edu/">Zhou Yu</a></h4>
                        <i>
                          Zhou Yu is an Assistant Professor in CS department at Columbia University. She obtained her Ph.D. from Carnegie Mellon University in 2017.  Zhou has built various dialog systems that have a real impact, such as a job interview training system, a depression screening system, and a second language learning system. Her research interest includes dialog systems, language understanding and generation, vision and language, human-computer interaction, and social robots. Zhou received an ACL 2019 best paper nomination, featured in Forbes 2018 30 under 30 in Science, and won the 2018 Amazon Alexa Prize.
                        </i>
                      </td>
                      
                    </tr>
                  </table>
                </td>
                <td style="padding:10px 10px 10px 10px;">
                  <h4>Personalized Persuasive Dialog Systems</h4>
                    <i>Abstract:</i> Dialog systems such as Alexa and Siri are everywhere in our lives. They can complete tasks such as booking flights, making restaurant reservations and training people for interviews. These systems are passively follow-along human needs.  What if the dialog systems have a different goal than users. We introduce dialog systems that can persuade users to donate to charities. We further improve the dialog model's coherence by tracking both semantic actions and conversational strategies from dialog history using finite-state transducers. Finally, we analyze some ethical concerns and human factors in deploying personalized persuasive dialog systems.
                </td>
              </tr>

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Jan 27</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/fuxin_li.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="http://web.engr.oregonstate.edu/~lif/">Fuxin Li</a></h4>
                        <i>
                          Dr. Fuxin Li is an Assistant Professor at Oregon State University.
                          Prior to this, he was a Research Scientist and Post-Doctoral Researcher at Georgia Tech; Research Scientist at Sminchisescu group, INS, University of Bonn.
                          Fuxin received his Ph.D. from the Institute of Automation, Chinese Academy of Sciences in 2008, and B.S. from Zhejiang University in 2001.

                          Fuxin's research direction is machine learning and computer vision, with a major interest in using and designing new machine learning algorithms to attack the structural data in images and videos, especially big data originating from videos.
                          <br>
                        </i>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Feb 03</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/vicente_ordonez.jpg" width="140px"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://www.vicenteordonez.com/">Vicente Ordóñez</a></h4>
                        <i>
                          Dr Vicente Ordóñez Román is an Assistant Professor in at the University of Virginia.
                          Prior to this, he was a Visiting Professor at Adobe Research and Visiting Researcher at the Allen Institute for AI. 
                          He received his Ph.D. in Computer Science at the University of North Carolina at Chapel Hill in 2015, an MS in Computer Science at Stony Brook University (SUNY), and an engineering degree at the Escuela Superior Politécnica del Litoral in Ecuador.

                          Vicente's research interests are in analyzing, and mining useful human insights from enormous amounts of images with associated text to improve visual recognition; building efficient visual recognition models that can perform high-level perceptual tasks; and fairness and accountability in machine learning applications. 
                          <br>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Feb 10</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/xialong_wang.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://xiaolonw.github.io/">Xiaolong Wang</a></h4>
                        <i>
                          Dr Xiaolong Wang is an Assistant Professor at UC San Diego.  
                          He was a postdoctoral fellow at UC Berkeley with Alexei Efros and Trevor Darrell,
                          and received his Ph.D. in Robotics from Carnegie Mellon University in 2019;
                          MS from Sun Yat-Sen University in 2014; 
                          and B.S. from South China Agricultural University in 2011.

                          Xiaolong is interested in Computer Vision, Machine Learning and Robotics, specifically on the topics of Self-Supervised Learning, Video Understanding, Common Sense Reasoning, RL and Robotics. 
                          <br>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Feb 15</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/abhishek_das.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://abhishekdas.com/">Abhishek Das</a></h4>
                        <i>
                          Dr Abhishek Das is a Research Scientist at Facebook AI Research.
                          Previously he received his Ph.D. in Computer Science at Georgia Tech, advised by Dhruv Batra, and working closely with Devi Parikh. He received his bachelor's degree from Indian Institute of Technology at Roorkee.

                          Abhishek's research focuses on deep learning and its applications in climate change, and in building agents that can see (computer vision), think (reasoning/interpretability), talk (language modeling), and act (reinforcement learning). 
                          <br>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>              

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Feb 22</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/xin_wang.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://eric-xw.github.io/">Xin (Eric) Wang</a></h4>
                        <i>
                          Dr Xin (Eric) Wang is an Assistant Professor of Computer Science and Engineering at UC Santa Cruz. 
                          He obtained his Ph.D. degree from UC Santa Barbara and Bachelor's degree from Zhejiang University, both in Computer Science. 

                          Eric's research interests include Natural Language Processing, Computer Vision, and Machine Learning, with an emphasis on building embodied AI agents that can communicate with humans using natural language to perform real-world tasks. 
                          <br>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Mar 01</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/damien_teney.png" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://www.damienteney.info/">Damien Teney</a></h4>
                        <i>
                          Dr Damien Teney is a Senior Researcher at the Australian Institute for Machine Learning, part of the University of Adelaide.  
                          He was previously affiliated with Carnegie Mellon University (USA), the University of Bath (UK), and the University of Innsbruck (Austria). 
                          Damien received his Ph.D. in Computer Science at the University of Liège (Belgium), advised by Justus Piater.
                          His research interests are at the intersection of computer vision and machine learning. 
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Mar 22</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/stefan_lee.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="http://web.engr.oregonstate.edu/~leestef/">Stefan Lee</a></h4>
                        <i>
                          Dr Stefan Lee is an Assistant Professor in EECS at Oregon State University. 
                          Previously he was a Research Scientist at Georgia Tech, and a Post-Doctoral Associate at Virginia Tech with Dhruv Batra.
                          He received his Ph.D. in Computer Science from Indiana University in 2016, and B.S. from University of West Florida in 2011.

                          Stefan's research focus is the development of agents that can perceive their environment and communicate about this understanding with humans in order to coordinate their actions to achieve mutual goals -- in short, agents that can see, talk, and act.

                          <br>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>        

              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Mar 29</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/yin_li.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://www.biostat.wisc.edu/~yli/">Yin Li</a></h4>
                        <i>
                          Dr Yin Li an Assistant Professor in the Department of Biostatistics and Medical Informatics and affiliate faculty in the Department of Computer Sciences at the University of Wisconsin-Madison. 
                          Previously, he obtained his PhD (with James M. Rehg) from the Georgia Institute of Technology and was a Postdoctoral Fellow (with Abhinav Gupta) at Carnegie Mellon University. 

                          Yin's primary research focus is computer vision, and is also interested in the applications of vision and learning for mobile health. His group develops methods and systems to automatically analyze human activities for healthcare applications. 
                          <br>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr> 


              <tr class="border-table">
                <td style="padding:10px;vertical-align:top">Apr 05</td>
                <td style="vertical-align:top">
                  <table>
                    <tr>
                      <td style="padding:10px;vertical-align:top"><img src="static/images/speakers/adriana_kovashka.jpg" width="140px" class="rounded-corner"></td>
                      <td style="padding:10px;vertical-align:top">
                        <h4><a href="https://people.cs.pitt.edu/~kovashka/">Adriana Kovashka</a></h4>
                        <i>
                          Dr Adriana Kovashka is an Assistant Professor in Computer Science at the University of Pittsburgh. 
                          She received her Ph.D. from the University of Texas at Austin in 2014 where she worked with Kristen Grauman, and B.A. in Computer Science and Media Studies from Pomona College, CA. 

                          Adriana's primary research area is computer vision, with overlap in machine learning, information retrieval, crowdsourcing, and natural language processing. Her work examines approaches for improving image retrieval with semantic visual attributes, and improving the communication between human and machine. 

                          <br>
                      </td>
                    </tr>
                  </table>
                </td>
              </tr>

             
                
            </table>
            </p> 
          </div>
        </div>

        <div class="container">
          <div class="hosts">
            <h3>Hosts </h3>
            <table align="center">
              <tr>
                <td class="person">
                  <a href="https://yezhouyang.engineering.asu.edu/"><b>Yezhou Yang</b></a>
                  <img src="static/images/yezhou.jpg" height="140px" class="rounded-corner"></a>
                </td>
                <td class="person">
                  <a href="https://www.public.asu.edu/~tgokhale/"><b>Tejas Gokhale</b></a>
                  <img src="static/images/tgokhale.png" height="140px" class="rounded-corner"></a>
                </td>
                <td class="person">
                  <a href="https://pratyay-banerjee.github.io/"><b>Pratyay Banerjee</b></a>
                  <img src="static/images/pratyay.jpg" height="140px" class="rounded-corner"></a>
                </td>
                <td class="person">
                  <a href="https://www.public.asu.edu/~zfang29/"><b>Zhiyuan Fang</b></a>
                  <img src="static/images/jacob.jpg" height="140px" class="rounded-corner"></a>
                </td>
                <td class="person">
                  <a href="https://www.public.asu.edu/~cbaral/"><b>Chitta Baral</b></a>
                  <img src="static/images/chitta.jpg" height="140px" class="rounded-corner"></a>
                </td>
              </tr>
            </table>

          </div>
          <p align='right'><i>Website maintained by Tejas Gokhale </i> </p>
        </div>



          </body>
      </html>
<script type="text/javascript">
  .white-bg{
    background:#ffffff !important;
}
</script>